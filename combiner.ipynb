{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "from Selector import Selector\n",
    "from Tablecreator import TableCreator\n",
    "from Inserter import Inserter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DB CREATION AND INSERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _exec(DB, statement):\n",
    "    DB.c.execute(statement)\n",
    "\n",
    "\n",
    "def createDB(DB_name):\n",
    "    testDB = TableCreator(DB_name)\n",
    "    testDB.createArticle()\n",
    "    testDB.createAuthor()\n",
    "    testDB.createHas()\n",
    "    testDB.createCitation()\n",
    "    testDB.closeConnect()\n",
    "    return\n",
    "\n",
    "name = 'test.db'\n",
    "createDB(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_paper(DB_name, idd, article, authors, year, citations = '', citated = '', keywords = '', pages = '', volume = '', issue = '', abstract = ''):\n",
    "    testDB = Inserter(DB_name)\n",
    "    if testDB.insertArticle(idd, article, keywords, pages, year, volume, issue, abstract):\n",
    "        for author in authors:\n",
    "            testDB.insertAuthor(author)\n",
    "            testDB.insertHas(idd, author)\n",
    "\n",
    "        for cit in citations:\n",
    "            testDB.insertCitations(idd, cit)\n",
    "        for cit in citated:\n",
    "            testDB.insertCitations(cit, idd)\n",
    "        testDB.closeConnect()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install elsapy\n",
    "\n",
    "from elsapy.elsclient import ElsClient\n",
    "from elsapy.elsprofile import ElsAuthor, ElsAffil\n",
    "from elsapy.elsdoc import FullDoc, AbsDoc\n",
    "from elsapy.elssearch import ElsSearch\n",
    "import json\n",
    "import requests\n",
    "\n",
    "## Debug imports\n",
    "from time import time\n",
    "    \n",
    "## Load configuration\n",
    "con_file = open(\"config.json\")\n",
    "config = json.load(con_file)\n",
    "con_file.close()\n",
    "\n",
    "## Initialize client\n",
    "client = ElsClient(config['apikey'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(name, numres):\n",
    "    res = []\n",
    "    if numres != -1:\n",
    "        return defsearch(numres, name)\n",
    "    else:\n",
    "        body = {\n",
    "            \"authors\": name,\n",
    "            \"loadedAfter\": \"2010-01-01T00:00:00Z\",\n",
    "            \"display\": {\n",
    "                \"show\": 1\n",
    "            }\n",
    "        }\n",
    "        r = requests.put(base, data=json.dumps(body), headers=headers).json()\n",
    "        return defsearch(r['resultsFound'], name)\n",
    "\n",
    "\n",
    "\n",
    "def defsearch(numres, name):\n",
    "    print('Found ' + str(numres) + ' results')\n",
    "    base = 'https://api.elsevier.com/content/search/sciencedirect'\n",
    "    headers = {\n",
    "        'x-els-apikey': config['apikey'],\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    res = []\n",
    "    for offset in range(0, numres, 100):\n",
    "            body = {\n",
    "                \"authors\": name,\n",
    "                \"loadedAfter\": \"2010-01-01T00:00:00Z\",\n",
    "                \"display\": {\n",
    "                    \"offset\": offset,\n",
    "                    \"show\": min(100, numres - offset)\n",
    "                }\n",
    "            }\n",
    "            r = requests.put(base, data=json.dumps(\n",
    "                body), headers=headers).json()\n",
    "            res += r['results']\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert ifo to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def push_info_to_db(searchres, name = 'test.db'):\n",
    "    for elem in searchres:\n",
    "        idd = elem['pii']\n",
    "        article = elem['sourceTitle']\n",
    "        auths = [author['name'] for author in elem['authors']]\n",
    "        year = int(elem['publicationDate'][:4])\n",
    "        insert_paper(name, idd, article, auths, year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 results\n",
      "Found 9 results\n",
      "Found 7 results\n",
      "Found 6 results\n",
      "Found 8 results\n",
      "Found 5 results\n",
      "Found 9 results\n",
      "Found 5 results\n",
      "Found 7 results\n",
      "Found 7 results\n",
      "Found 7 results\n",
      "Found 5 results\n",
      "Found 9 results\n",
      "Found 5 results\n",
      "Found 7 results\n",
      "Found 10 results\n",
      "Found 5 results\n",
      "Found 5 results\n",
      "Found 10 results\n",
      "Found 8 results\n",
      "Found 10 results\n",
      "Found 6 results\n",
      "Found 8 results\n",
      "Found 9 results\n",
      "Found 10 results\n",
      "Found 7 results\n",
      "Found 6 results\n",
      "Found 7 results\n",
      "Found 6 results\n",
      "Found 7 results\n",
      "Found 8 results\n",
      "Found 9 results\n",
      "Found 5 results\n",
      "Found 5 results\n",
      "Found 6 results\n",
      "Found 10 results\n",
      "Found 6 results\n",
      "Found 6 results\n",
      "Found 7 results\n",
      "Found 6 results\n",
      "Found 10 results\n",
      "Found 8 results\n",
      "Found 5 results\n",
      "Found 9 results\n",
      "Found 10 results\n",
      "Found 9 results\n",
      "Found 9 results\n",
      "Found 10 results\n",
      "Found 7 results\n",
      "Found 10 results\n",
      "Found 7 results\n",
      "Found 6 results\n",
      "Found 7 results\n",
      "Found 8 results\n",
      "Found 9 results\n",
      "Found 5 results\n",
      "Found 5 results\n",
      "Found 6 results\n",
      "Found 9 results\n",
      "Found 5 results\n",
      "Found 7 results\n",
      "Found 7 results\n",
      "Found 10 results\n",
      "Found 7 results\n",
      "Found 10 results\n",
      "Found 9 results\n",
      "Found 7 results\n",
      "Found 5 results\n",
      "Found 5 results\n",
      "Found 6 results\n",
      "Found 7 results\n",
      "Found 8 results\n",
      "Found 5 results\n",
      "Found 6 results\n",
      "Found 6 results\n",
      "Found 6 results\n",
      "Found 7 results\n",
      "Found 9 results\n",
      "Found 6 results\n",
      "Found 7 results\n",
      "Found 9 results\n",
      "Found 7 results\n",
      "Found 9 results\n",
      "Found 7 results\n",
      "Found 6 results\n",
      "Found 8 results\n",
      "Found 10 results\n",
      "Found 10 results\n",
      "Found 7 results\n",
      "Found 10 results\n",
      "Found 9 results\n",
      "Found 6 results\n",
      "Found 8 results\n",
      "Found 9 results\n",
      "Found 10 results\n",
      "Found 7 results\n",
      "Found 6 results\n",
      "Found 7 results\n",
      "Found 9 results\n",
      "Found 10 results\n",
      "Found 8 results\n",
      "Found 6 results\n",
      "Found 8 results\n",
      "Found 5 results\n",
      "Found 6 results\n",
      "Found 9 results\n",
      "Found 6 results\n",
      "Found 8 results\n",
      "Found 9 results\n",
      "Found 7 results\n",
      "Found 9 results\n",
      "Found 6 results\n",
      "Found 5 results\n",
      "Found 10 results\n",
      "Found 8 results\n",
      "Found 7 results\n",
      "Found 9 results\n",
      "Found 9 results\n",
      "Found 7 results\n",
      "Found 8 results\n",
      "Found 10 results\n",
      "Found 6 results\n",
      "Found 10 results\n",
      "Found 9 results\n",
      "Found 5 results\n",
      "Found 10 results\n",
      "Found 9 results\n",
      "Found 8 results\n",
      "Found 9 results\n",
      "Found 8 results\n",
      "Found 5 results\n",
      "Found 8 results\n",
      "Found 10 results\n",
      "Found 6 results\n",
      "Found 5 results\n",
      "Found 7 results\n",
      "Found 9 results\n",
      "Found 6 results\n",
      "Found 9 results\n",
      "Found 7 results\n",
      "Found 7 results\n",
      "Found 6 results\n",
      "Found 5 results\n",
      "Found 5 results\n",
      "Found 7 results\n",
      "Found 8 results\n",
      "Found 8 results\n",
      "Found 5 results\n",
      "Found 10 results\n",
      "Found 9 results\n",
      "Found 10 results\n",
      "Found 5 results\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "from queue import Queue\n",
    "\n",
    "q = Queue()\n",
    "\n",
    "# get random search result\n",
    "s = search('Markov', 1)\n",
    "push_info_to_db(s)\n",
    "\n",
    "# put first authors in the queue\n",
    "for auth in s[0]['authors']:\n",
    "    q.put(auth['name'])\n",
    "    \n",
    "# search co-authors in queue\n",
    "threshold = 150\n",
    "i = 0\n",
    "while not q.empty() and i <= threshold:\n",
    "    searchres = search(q.get_nowait(), randint(5, 10))\n",
    "    push_info_to_db(searchres)\n",
    "    for res in searchres:\n",
    "        for author in res['authors']:\n",
    "            q.put(author['name'])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Authors Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_authors(DB_name):\n",
    "    testDB = Selector(DB_name)\n",
    "    df = testDB.make_df_authors()\n",
    "    testDB.closeConnect()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_authors_for_year(DB_name, year):\n",
    "    testDB = Selector(DB_name)\n",
    "    df = testDB.make_df_for_year(year)\n",
    "    testDB.closeConnect()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph_from_pandas_df(df):\n",
    "    \"\"\" Takes pandas dataframe and create networkx graph. We suggest every row in df\n",
    "        is an article with next columns: 'list of authors' (list of strings)\n",
    "    \"\"\"\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    for num, row in df.iterrows():\n",
    "        authors_list = row['authors_list']\n",
    "        # connect every one and update edges\n",
    "        for i in range(len(authors_list)):\n",
    "            for j in range(i + 1, len(authors_list)):\n",
    "                from_, to_ = authors_list[i], authors_list[j]\n",
    "                new_weight = (G[from_][to_]['weight'] if G.has_edge(from_, to_) else 0) + 1\n",
    "                G.add_edge(from_, to_, weight=new_weight)\n",
    "        \n",
    "    return G    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I split graph into 5 independent pieces consisting of 5 years each. Also i use data for 2019 year as test for target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'test.db'\n",
    "df = create_df_authors_for_year(name, 1994)\n",
    "dffs = []\n",
    "grapfs = []\n",
    "for i in range(1990, 2020, 5):\n",
    "    dffs.append(create_df_authors_for_year(name, i))\n",
    "    dffs[-1] = dffs[-1].append(create_df_authors_for_year(name, i + 1))\n",
    "    dffs[-1] = dffs[-1].append(create_df_authors_for_year(name, i + 2))\n",
    "    dffs[-1] = dffs[-1].append(create_df_authors_for_year(name, i + 3))\n",
    "    dffs[-1] = dffs[-1].append(create_df_authors_for_year(name, i + 4))\n",
    "    grapfs.append(create_graph_from_pandas_df(dffs[-1]))\n",
    "test = create_df_authors_for_year(name, 2019)\n",
    "testgraph = create_graph_from_pandas_df(test)\n",
    "G = create_graph_from_pandas_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "29\n",
      "31\n",
      "30\n",
      "2438\n",
      "4859\n",
      "941\n"
     ]
    }
   ],
   "source": [
    "len(list(G.adjacency()))\n",
    "for i in grapfs:\n",
    "    print(len(list(i.adjacency())))\n",
    "print(len(list(testgraph.adjacency())))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here i make features. I make:\n",
    "common neighbours\n",
    "Jaccard’s coefficient\n",
    "Shortest path:\n",
    "Katz score\n",
    "node2vec embending of size 10\n",
    "density of the graph\n",
    "\n",
    "\n",
    "common neighbours\n",
    "Jaccard’s coefficient\n",
    "Shortest path:\n",
    "Katz score\n",
    "for same nodes in previous interval of years\n",
    "\n",
    "\n",
    "Also i use only 10000 first node-pairs for train set and 1000 first node-pairs for test set as there are a lot of nodes and taking them all would take a lot of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_features(grapha, graphb, emembs, prev):\n",
    "    beta = 0.1\n",
    "    subs = (grapha.subgraph(c) for c in nx.connected_components(grapha))\n",
    "    nodes = list(grapha.nodes)\n",
    "    features = []\n",
    "    target = []\n",
    "    wow = 0\n",
    "    fl = False\n",
    "    for i in range(len(nodes) - 1):\n",
    "        if(fl):\n",
    "            break\n",
    "        for j in range(i + 1, len(nodes)):\n",
    "            wow += 1\n",
    "            if(wow % 1000 == 0):\n",
    "                print(wow)\n",
    "                fl = True\n",
    "                break\n",
    "            if not grapha.has_edge(nodes[i], nodes[j]):\n",
    "                features.append([nodes[i], nodes[j]])\n",
    "                if(graphb.has_edge(nodes[i], nodes[j])):\n",
    "                #    print('daticho')\n",
    "                    target.append(1)\n",
    "                else:\n",
    "                    target.append(0)\n",
    "                features[-1].append(len(list(nx.common_neighbors(grapha, nodes[i], nodes[j]))))\n",
    "                features[-1].append(len(list(nx.common_neighbors(grapha, nodes[i], nodes[j]))) / (grapha.degree(nodes[i]) + grapha.degree(nodes[j]) - len(list(nx.common_neighbors(grapha, nodes[i], nodes[j])))))\n",
    "                if(nx.has_path(grapha, nodes[i], nodes[j])):\n",
    "                    features[-1].append(nx.shortest_path_length(grapha, nodes[i], nodes[j]))\n",
    "                    paths = nx.all_simple_paths(grapha, nodes[i], nodes[j], cutoff=5)\n",
    "                    res = 0\n",
    "                    for i11 in paths:\n",
    "                        res += beta ** (len(i11))\n",
    "                    features[-1].append(res)\n",
    "                    #mcmf = nx.max_flow_min_cost(grapha, nodes[i], nodes[j], capacity='weight', weight='None')\n",
    "                    #features[-1].append(mcmf)\n",
    "                    #res = 0\n",
    "                   # for i1 in mcmf[nodes[i]]:\n",
    "                  #      res += mcmf[nodes[i]][i1]\n",
    "                 #   features[-1].append(res)\n",
    "                #    features[-1].append(nx.cost_of_flow(grapha, mcmf))\n",
    "        #            print(features[-1][-1], features[-1][-2])\n",
    "                else:\n",
    "                    features[-1].append(10000)\n",
    "                    features[-1].append(0)\n",
    "                    #features[-1].append(0)\n",
    "                for k in emembs[nodes[i], nodes[j]]:\n",
    "                    features[-1].append(k)\n",
    "                features[-1].append(nx.density(grapha))\n",
    "                flflfl = True\n",
    "                for k in prev:\n",
    "                    if nodes[i] == k[0] and nodes[j] == k[1]:\n",
    "                        features[-1].append(k[2])\n",
    "                        features[-1].append(k[3])\n",
    "                        features[-1].append(k[4])\n",
    "                        features[-1].append(k[5])\n",
    "                        flflfl = False\n",
    "                        break\n",
    "                    elif nodes[i] < k[0] or (nodes[i] == k[0] and nodes[j] < k[1]):\n",
    "                        features[-1].append(0)\n",
    "                        features[-1].append(0)\n",
    "                        features[-1].append(0)\n",
    "                        features[-1].append(0)\n",
    "                        flflfl = False\n",
    "                        break\n",
    "                if(prev == [] or flflfl):\n",
    "                    features[-1].append(0)\n",
    "                    features[-1].append(0)\n",
    "                    features[-1].append(0)\n",
    "                    features[-1].append(0)\n",
    "    return (features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here i pre-count embendings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:   0%|          | 0/13 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities: 100%|██████████| 13/13 [00:00<00:00, 1446.12it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Generating walks (CPU: 1):   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Generating walks (CPU: 1): 100%|██████████| 5/5 [00:00<00:00, 57.56it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:   0%|          | 0/29 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities: 100%|██████████| 29/29 [00:00<00:00, 1320.29it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Generating walks (CPU: 1):   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Generating walks (CPU: 1):  80%|████████  | 4/5 [00:00<00:00, 34.25it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Generating walks (CPU: 1): 100%|██████████| 5/5 [00:00<00:00, 23.30it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:   0%|          | 0/31 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities: 100%|██████████| 31/31 [00:00<00:00, 1552.74it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Generating walks (CPU: 1):   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Generating walks (CPU: 1):  80%|████████  | 4/5 [00:00<00:00, 36.09it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Generating walks (CPU: 1): 100%|██████████| 5/5 [00:00<00:00, 26.64it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities: 100%|██████████| 30/30 [00:00<00:00, 751.23it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Generating walks (CPU: 1):   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Generating walks (CPU: 1):  80%|████████  | 4/5 [00:00<00:00, 39.67it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Generating walks (CPU: 1): 100%|██████████| 5/5 [00:00<00:00, 28.13it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:   0%|          | 0/2438 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:   1%|          | 26/2438 [00:00<00:09, 259.05it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:   4%|▍         | 93/2438 [00:00<00:07, 316.19it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:   7%|▋         | 165/2438 [00:00<00:05, 379.65it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  10%|█         | 252/2438 [00:00<00:04, 456.30it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  13%|█▎        | 306/2438 [00:00<00:04, 462.78it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  16%|█▋        | 399/2438 [00:00<00:03, 544.56it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  19%|█▉        | 463/2438 [00:00<00:03, 534.62it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  23%|██▎       | 554/2438 [00:00<00:03, 606.66it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  27%|██▋       | 649/2438 [00:00<00:02, 680.28it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  30%|██▉       | 726/2438 [00:01<00:02, 656.59it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  33%|███▎      | 801/2438 [00:01<00:02, 681.30it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  36%|███▌      | 878/2438 [00:01<00:02, 705.68it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  40%|███▉      | 974/2438 [00:01<00:01, 765.07it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  44%|████▍     | 1070/2438 [00:01<00:01, 806.18it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  47%|████▋     | 1154/2438 [00:01<00:01, 809.36it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  51%|█████     | 1238/2438 [00:01<00:01, 809.24it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  55%|█████▍    | 1332/2438 [00:01<00:01, 842.57it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  59%|█████▊    | 1428/2438 [00:01<00:01, 872.66it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  64%|██████▍   | 1555/2438 [00:01<00:00, 961.21it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  68%|██████▊   | 1655/2438 [00:02<00:00, 956.26it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  72%|███████▏  | 1754/2438 [00:02<00:00, 906.85it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  76%|███████▌  | 1848/2438 [00:02<00:00, 840.35it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  81%|████████  | 1970/2438 [00:02<00:00, 924.01it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  85%|████████▍ | 2067/2438 [00:02<00:00, 913.78it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  90%|████████▉ | 2184/2438 [00:02<00:00, 975.98it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  94%|█████████▎| 2285/2438 [00:02<00:00, 916.67it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  98%|█████████▊| 2400/2438 [00:02<00:00, 974.00it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities: 100%|██████████| 2438/2438 [00:02<00:00, 828.40it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Generating walks (CPU: 1):   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Generating walks (CPU: 1):  40%|████      | 2/5 [00:04<00:06,  2.26s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Generating walks (CPU: 1):  60%|██████    | 3/5 [00:08<00:05,  2.75s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Generating walks (CPU: 1):  80%|████████  | 4/5 [00:28<00:07,  7.80s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Generating walks (CPU: 1): 100%|██████████| 5/5 [00:31<00:00,  6.50s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:   0%|          | 0/4859 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:   0%|          | 13/4859 [00:00<00:37, 128.91it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:   1%|          | 37/4859 [00:00<00:32, 148.91it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:   1%|▏         | 68/4859 [00:00<00:27, 175.56it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:   2%|▏         | 88/4859 [00:00<00:26, 181.33it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:   3%|▎         | 146/4859 [00:00<00:20, 227.94it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:   4%|▍         | 193/4859 [00:00<00:17, 266.01it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:   5%|▌         | 261/4859 [00:00<00:14, 324.13it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:   7%|▋         | 328/4859 [00:00<00:11, 382.97it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:   8%|▊         | 379/4859 [00:00<00:11, 393.94it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:   9%|▉         | 427/4859 [00:01<00:10, 403.91it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  10%|▉         | 474/4859 [00:01<00:11, 378.16it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  11%|█         | 521/4859 [00:01<00:11, 393.80it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  12%|█▏        | 564/4859 [00:01<00:12, 349.14it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  13%|█▎        | 610/4859 [00:01<00:11, 375.57it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  13%|█▎        | 654/4859 [00:01<00:10, 391.95it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  15%|█▌        | 736/4859 [00:01<00:08, 464.06it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  16%|█▋        | 796/4859 [00:01<00:08, 495.63it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  18%|█▊        | 862/4859 [00:01<00:07, 534.56it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  19%|█▉        | 946/4859 [00:02<00:06, 591.35it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  21%|██        | 1011/4859 [00:02<00:07, 492.21it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  22%|██▏       | 1067/4859 [00:02<00:08, 444.21it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  23%|██▎       | 1121/4859 [00:02<00:08, 465.73it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  24%|██▍       | 1172/4859 [00:02<00:07, 469.16it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  25%|██▌       | 1234/4859 [00:02<00:07, 503.84it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  27%|██▋       | 1288/4859 [00:02<00:07, 502.91it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  28%|██▊       | 1376/4859 [00:02<00:06, 573.90it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  30%|██▉       | 1439/4859 [00:03<00:06, 551.26it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  31%|███       | 1498/4859 [00:03<00:07, 462.25it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  32%|███▏      | 1556/4859 [00:03<00:06, 489.94it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  33%|███▎      | 1623/4859 [00:03<00:06, 530.17it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  35%|███▍      | 1685/4859 [00:03<00:05, 551.93it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  36%|███▋      | 1762/4859 [00:03<00:05, 601.99it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  38%|███▊      | 1826/4859 [00:03<00:05, 604.51it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  39%|███▉      | 1898/4859 [00:03<00:04, 632.63it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  41%|████      | 1973/4859 [00:03<00:04, 662.22it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  42%|████▏     | 2041/4859 [00:04<00:05, 549.73it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  43%|████▎     | 2101/4859 [00:04<00:05, 476.85it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  44%|████▍     | 2154/4859 [00:04<00:05, 487.79it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities:  46%|████▌     | 2219/4859 [00:04<00:05, 526.19it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  48%|████▊     | 2312/4859 [00:04<00:04, 604.00it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  49%|████▉     | 2383/4859 [00:04<00:03, 630.92it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  50%|█████     | 2451/4859 [00:04<00:03, 615.43it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  52%|█████▏    | 2516/4859 [00:04<00:04, 541.39it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  53%|█████▎    | 2595/4859 [00:05<00:03, 596.70it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  55%|█████▍    | 2660/4859 [00:05<00:04, 540.29it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  56%|█████▌    | 2719/4859 [00:05<00:03, 551.44it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  57%|█████▋    | 2783/4859 [00:05<00:03, 574.03it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  59%|█████▊    | 2843/4859 [00:05<00:03, 580.15it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  60%|██████    | 2931/4859 [00:05<00:02, 645.02it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  62%|██████▏   | 3010/4859 [00:05<00:02, 675.87it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  63%|██████▎   | 3081/4859 [00:05<00:02, 613.30it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  65%|██████▍   | 3146/4859 [00:05<00:02, 579.17it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  66%|██████▌   | 3207/4859 [00:06<00:03, 506.42it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  67%|██████▋   | 3277/4859 [00:06<00:02, 551.14it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  70%|██████▉   | 3378/4859 [00:06<00:02, 637.09it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  71%|███████   | 3450/4859 [00:06<00:02, 609.47it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  73%|███████▎  | 3543/4859 [00:06<00:01, 676.17it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  74%|███████▍  | 3617/4859 [00:06<00:01, 688.39it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  76%|███████▌  | 3698/4859 [00:06<00:01, 719.23it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  79%|███████▊  | 3816/4859 [00:06<00:01, 813.24it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  81%|████████  | 3943/4859 [00:06<00:01, 909.92it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  84%|████████▎ | 4068/4859 [00:07<00:00, 988.79it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  86%|████████▋ | 4191/4859 [00:07<00:00, 1048.34it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  89%|████████▊ | 4303/4859 [00:07<00:00, 1031.00it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  91%|█████████ | 4433/4859 [00:07<00:00, 1094.13it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  94%|█████████▎| 4547/4859 [00:07<00:00, 1104.79it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  96%|█████████▌| 4661/4859 [00:07<00:00, 1096.33it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities:  99%|█████████▊| 4795/4859 [00:07<00:00, 1151.11it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computing transition probabilities: 100%|██████████| 4859/4859 [00:07<00:00, 625.71it/s] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Generating walks (CPU: 1):   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Generating walks (CPU: 1):  40%|████      | 2/5 [00:06<00:09,  3.01s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Generating walks (CPU: 1):  60%|██████    | 3/5 [00:11<00:07,  3.89s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Generating walks (CPU: 1):  80%|████████  | 4/5 [00:19<00:04,  4.93s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Generating walks (CPU: 1): 100%|██████████| 5/5 [00:26<00:00,  5.53s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ememembes = []\n",
    "for i in grapfs:\n",
    "    model = Node2Vec(i, dimensions=10, walk_length=5, num_walks=5)\n",
    "    model = model.fit()\n",
    "    ememembes.append(HadamardEmbedder(keyed_vectors=model.wv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(grapfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here i make train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "10000\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "feats1, tars1 = [], []\n",
    "for i in range(5):\n",
    "    if(i == 0):\n",
    "        res = make_features(grapfs[i], grapfs[i + 1], ememembes[i], [])\n",
    "    else:\n",
    "        res = make_features(grapfs[i], grapfs[i + 1], ememembes[i], feats1[-1])\n",
    "    feats1.append(res[0])\n",
    "    tars1.append(res[1])\n",
    "    print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainF, trainT = [], []\n",
    "for i in range(5):\n",
    "    trainF += feats1[i]\n",
    "    trainT += tars1[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 21\n"
     ]
    }
   ],
   "source": [
    "maxxxxx = 21\n",
    "for i in trainF:\n",
    "    maxxxxx = min(len(i), maxxxxx)\n",
    "print(maxxxxx, len(trainF[0]))\n",
    "for i in range(len(trainF)):\n",
    "    trainF[i] = trainF[i][2:]\n",
    "    trainF[i] = np.array(trainF[i])\n",
    "trainF = np.array(trainF)\n",
    "trainF = (trainF - trainF.mean()) / trainF.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here i train logreg model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelll = LogisticRegression()\n",
    "modelll.fit(trainF, trainT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here i make test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "testF, testT = make_features(grapfs[5], testgraph, ememembes[5], feats1[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(testF)):\n",
    "    if(i % 1000 == 999):\n",
    "        print(i)\n",
    "    testF[i] = testF[i][2:]\n",
    "    testF[i] = np.array(testF[i])\n",
    "testF = np.array(testF)\n",
    "testF = (testF - trainF.mean()) / trainF.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "predlr = modelll.predict(testF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here i train knn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "modelll2 = KNeighborsClassifier(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelll2.fit(trainF, trainT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "predknn = modelll2.predict(testF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here i train MLPclassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "modelll3 = MLPClassifier(alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelll3.fit(trainF, trainT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "predmlp = modelll3.predict(testF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "reses = [[predknn, 'knn'], [predlr, 'logistic regression'], [predmlp, 'mlp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(testT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(predknn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(predlr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(predmlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems, that there were no ones in test target(in train target there were less than 1% of ones). All classifiers did their work well with accuracy equals to 1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
